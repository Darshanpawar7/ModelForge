dataset:
  path: "datasets/dataset.csv"
  format: csv
  delimiter: ","

input_features:
  - name: text
    type: text
    encoder: parallel_cnn
    params:
      embedding_size: 256
      num_filters: 256
      filter_sizes: [3, 4, 5]
      num_fc_layers: 2
      vocab_size: 10000
      fc_size: 256
      dropout: 0.5
      output_size: 3
    

output_features:
  - name: sentiment
    type: category
    num_classes : 3

combiner:
  type: concat
  output_size: 512

decoder:
  vocab_size: 10000
  embedding_size: 256
  hidden_size: 512
  dropout: 0.5    

training:
  batch_size: 32
  epochs: 10
  learning_rate: 0.001
  split:
    train: 0.7
    test: 0.2
    validation: 0.1

preprocessing:
  split:
    train: 0.7
    test: 0.2
    validation: 0.1
    random_seed: 42
  text:
    lower_case: true
    remove_punctuation: true
    remove_stopwords: true
    stemming: false
    tokenization:
      method: word
