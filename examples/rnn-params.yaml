dataset:
  path: "datasets/dataset.csv"
  format: csv
  delimiter: ","

input_features:
  - name: text
    type: text
    encoder: rnn
    params:
      embedding_size: 100
      state_size: 128
      output_size: 3
      num_layers: 2
      bidirectional: true
      cell_type: lstm
      representation: dense
      recurrent_dropout: 0.2
      recurrent_initializer: glorot_uniform
      use_bias: true
      unit_forget_bias: true
      weights_initializer: glorot_uniform
      reduce_output: mean
      num_fc_layers: 1
      norm: true
      vocab_size : 10000

combiner:
  type: concat
  output_size: 512

decoder:
  vocab_size: 10000
  embedding_size: 256
  hidden_size: 512
  dropout: 0.5 

training:
  batch_size: 32
  epochs: 10
  learning_rate: 0.001
  split:
    train: 0.7
    test: 0.2
    validation: 0.1

preprocessing:
  split:
    train: 0.7
    test: 0.2
    validation: 0.1
    random_seed: 42
  text:
    lower_case: true
    remove_punctuation: true
    remove_stopwords: true
    stemming: false
    tokenization:
      method: word